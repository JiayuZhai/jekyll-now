---
layout: post
title: 海上风场SCADA数据缺失智能修复-比赛经验总结
---

## 模型，环境，背景

1. 模型框架：Pytorch，数据框架：pandas，预处理框架：sklearn
2. 模型：Seq2Seq(GRU) -> Seq2Seq(GRU-D)
3. 背景：修复多个机器（文件）中部分缺失和完全缺失的字段

## 经验

### 数据处理部分
1. 海量数据（内存不足以全部载入）的处理，利用`torch.utils.data.Dataset`的实现以及`torch.utils.data.DataLoader`来实现
	1. `torch.utils.data.Dataset`的实现中，记录每个文件的记录条数，利用counter追踪当前要get的记录位于的文件位置，注意counter在epoch之间的复位
	2. 利用transforms对数据进行预处理
	3. `__getitem__`的返回为单条数据，batch化的操作是通过`torch.utils.data.DataLoader`实现的
2. 数据预处理的部分，分离散值，连续值，缺失值
	1. 离散值用onehot处理，大量数据通过记录不同categories的字典，缺失的离散值用全零值代替，即使用`ignore`参数
	2. 连续值用standardization处理，大量数据通过记录 和，平方的和，数据的个数，手动计算mean和std，然后用`[mean-sqrt(1.5*std),mean+sqrt(1.5*std)]`来拟合，缺失的连续值用零（即均值）代替
	3. 注意对预处理参数（离散值的字典，连续值的均值方差）作为metadata的保存
3. 未分离训练验证部分的海量数据，生成由随机数向量决定的训练集记录mask，并用counter追踪当前数据是否加入到验证集，并对验证集数据进行transforms，注意counter在epoch之间的复位

### 训练框架模型部分
1. 严格注意`torch.view()`和`torch.reshape()`的使用情况，与`torch.transpose()`或`torch.t()`的情况做出区分
2. 注意Seq2Seq模型中initHidden的设置
	1. encoder的为全零向量
	2. decoder的为encoder最后的hidden
3. 注意矩阵相乘matmul，对位相乘mul的区别

### 其他部分
1. 注意进度报告的及时性
2. 注意合作者之间知识体系的差异性
3. 注意总结经验
4. 注意放弃项目的及时性
